---
title: "Data Wrangling"
output: html_document
---

Classwork:

# Data wrangling  1

```{r}
library(tidyverse)

litters_data = read_csv(file = "./data_import_examples/FAS_litters.csv")

litters_data = janitor::clean_names(litters_data)
names(litters_data)

pups_data = read_csv(file = "./data_import_examples/FAS_pups.csv")
pups_data = janitor::clean_names(pups_data)
head(litters_data, 5)

#skim is like proc contents but better
skimr::skim(litters_data)

litters_data = read_csv(file = "./data_import_examples/FAS_litters.csv",skip = 10, col_names = FALSE)

#using col_types
litters_data = read_csv(file = "./data_import_examples/FAS_litters.csv",
  col_types = cols(
    Group = col_character(),
    `Litter Number` = col_character(),
    `GD0 weight` = col_double(),
    `GD18 weight` = col_double(),
    `GD of Birth` = col_integer(),
    `Pups born alive` = col_integer(),
    `Pups dead @ birth` = col_integer(),
    `Pups survive` = col_integer()
  )
)

library(readxl)
mlb11_data = read_excel("data_import_examples/mlb11.xlsx", n_max = 20)
head(mlb11_data, 5)

library(haven)
pulse_data = read_sas("./data_import_examples/public_pulse_data.sas7bdat")
head(pulse_data, 5)

#write_* can be used to export data in different forms

```

# Data wrangling II


```{r}
litters_data = read_csv(file = "./data_import_examples/FAS_litters.csv")

litters_data = janitor::clean_names(litters_data)

options(tibble.print_min = 3)
skinny_litter = select(litters_data, group:gd_of_birth)

litters_2 = select(litters_data, -pups_survive, GROUP = group)

#select_helpers find columns with specified parts
litters_different = select(litters_data, litter_number, pups_survive, everything())
#everything() keeps all but let you rearrange

#relocate and rename can be used instead of select

mutate(litters_data, wt_gain = gd18_weight - gd0_weight, group = str_to_lower(group))

#arrange is a form of sort
#relocate is for columns, arrange is for sorting rows

head(arrange(litters_data, group, pups_born_alive), 10)

#using piping makes code like a sas datastep
litters_data = 
  read_csv("./data_import_examples/FAS_litters.csv", col_types = "ccddiiii") %>%
  janitor::clean_names() %>%
  select(-pups_survive) %>%
  mutate( wt_gain = gd18_weight - gd0_weight, group = str_to_lower(group)) %>% 
  drop_na(wt_gain)
```
# Data Wrangling III

```{R}
pulse_data = haven::read_sas("./data_import_examples/public_pulse_data.sas7bdat")   %>% janitor::clean_names()
head(pulse_data)

#wide format to long format

pulse_long = pulse_data %>% pivot_longer(bdi_score_bl:bdi_score_12m , 
names_to = "visit",
names_prefix = "bdi_score_",
values_to = "bdi_score") %>% relocate(id, visit) %>% mutate(visit=recode(visit, "bl" = "00m"))

head(pulse_long)
```
Stacking data and binding rows

```{R}
fellowship_data = 
  readxl::read_excel("./data_import_examples/LotR_Words.xlsx", range = "B3:D6") %>% mutate(movie= "fellowship_ring")

two_towers_data = 
  readxl::read_excel("./data_import_examples/LotR_Words.xlsx", range = "F3:H6") %>% mutate(movie= "two_towers")

return_king_data = 
  readxl::read_excel("./data_import_examples/LotR_Words.xlsx", range = "J3:L6") %>% mutate(movie= "return_king")

lotr_tidy= bind_rows(fellowship_data, two_towers_data, return_king_data) %>%
  janitor::clean_names() %>% 
  relocate(movie) %>% 
  pivot_longer(female:male, names_to = "gender", values_to = "words")

```
joining datasets

```{R}
pup_data = 
  read_csv("./data_import_examples/FAS_pups.csv", col_types = "ciiiii") %>%
  janitor::clean_names() %>%
  mutate(sex = recode(sex, `1` = "male", `2` = "female")) 

litter_data = 
  read_csv("./data_import_examples/FAS_litters.csv", col_types = "ccddiiii") %>%
  janitor::clean_names() %>%
  separate(group, into = c("dose", "day_of_tx"), sep = 3) %>%
  relocate(litter_number) %>%
  mutate(
    wt_gain = gd18_weight - gd0_weight,
    dose = str_to_lower(dose))
#join litter data on to pups

left_join (pup_data, litter_data, by = "litter_number")
```

